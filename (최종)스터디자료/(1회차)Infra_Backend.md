# 백엔드 & 인프라 스터디 1 회차 문제
2025-09-19
작성자 : 김호중

## 데이터베이스 설계: 정규화와 비정규화 사이의 트레이드오프

### 상황
빠르게 성장하는 이커머스 플랫폼의 백엔드를 개발하고 있습니다. 초기 데이터베이스는 **제 3 정규형(3NF)**을 철저히 준수하여 설계되었고, 데이터의 중복이 거의 없어 쓰기(Write) 성능과 데이터 정합성 측면에서 매우 만족스러웠습니다.

하지만 서비스의 핵심 페이지인 상품 목록 페이지의 로딩 속도가 사용자가 늘어남에 따라 점점 느려지는 문제가 발생했습니다. 이 페이지는 상품명(products), 카테고리명(categories), 대표 이미지 URL(product_images), 평균 별점(reviews) 정보를 한 번에 보여주어야 합니다. 이 정보를 가져오기 위해 4 개의 테이블을 JOIN 해야 했고, 특히 수백만 건의 데이터가 쌓인 reviews 테이블에 AVG()와 COUNT() 같은 집계 함수를 실행하는 것이 극심한 성능 병목을 유발하는 원인으로 지목되었습니다.

### 문제

1. **병목의 근본 원인 분석**: '읽기' 연산이 많은 위 시나리오에서, 교과서적으로 '잘 설계된' 정규화된 스키마가 오히려 어떻게 성능 저하의 주범이 되는지 조인(JOIN)의 비용과 실시간 집계의 부하 관점에서 구체적으로 설명하시오.

> **[답변]**
> **1. 조인(JOIN)의 비용 증가:**
> 정규화된 스키마는 데이터 중복을 피하기 위해 데이터를 여러 테이블로 쪼개기 때문에, 조회 시 필연적으로 `JOIN` 연산이 필요합니다. 데이터 양이 적을 때는 문제가 없으나, 테이블의 행(Row) 수가 수백만 건으로 늘어나면 다음과 같은 비용이 기하급수적으로 증가합니다.
> - **Nested Loop Join 부하:** 인덱스를 타더라도 디스크 Random I/O가 4번의 테이블 이동마다 발생합니다.
> - **메모리 사용량:** Hash Join 등을 사용할 때 대용량 데이터를 메모리에 올리는 오버헤드가 발생합니다.
>
> **2. 실시간 집계(Aggregate)의 치명적 부하:**
> 특히 `AVG()`나 `COUNT()` 같은 집계 함수는 `reviews` 테이블의 관련된 모든 행을 읽어야 결과를 낼 수 있습니다.
> - **Full Scan/Index Scan:** 특정 상품의 리뷰가 10만 개라면, 목록에 있는 상품 20개를 보여주기 위해 논리적으로 200만 개의 레코드를 매번 읽고 계산해야 합니다. 이는 CPU 연산 비용보다 디스크 I/O 병목을 유발하는 주범이 됩니다.

2. **비정규화 전략 제시**: 이 문제를 해결하기 위해 products 테이블의 스키마를 어떻게 변경하시겠습니까? products 테이블에 어떤 컬럼들을 추가하여 JOIN 과 실시간 집계를 최소화할 수 있을지, 구체적인 비정규화 스키마 변경안을 제시하시오.

> **[답변]**
> 읽기 성능 최적화를 위해 `products` 테이블에 자주 조회되는 데이터를 중복 저장하는 **반정규화(Denormalization)**를 수행합니다.
>
> **변경 스키마 제안 (`products` 테이블 추가 컬럼):**
> - `category_name` (VARCHAR): `categories` 테이블 조인 제거 목적
> - `main_image_url` (VARCHAR): `product_images` 테이블 조인 제거 목적 (대표 이미지 1개만 필요한 경우)
> - `avg_rating` (DECIMAL): `reviews` 테이블 실시간 AVG() 연산 제거 목적
> - `review_count` (INT): `reviews` 테이블 실시간 COUNT() 연산 제거 목적
>
> 이렇게 변경하면 상품 목록 조회 시 `JOIN`이나 `GROUP BY` 없이 `products` 테이블 하나만 단순 조회(`SELECT * FROM products`)하면 되므로 성능이 획기적으로 개선됩니다.

3. **새로운 트레이드오프 분석**: 제시한 비정규화 전략은 읽기 성능을 극적으로 향상시키지만, '쓰기' 연산의 복잡성과 데이터 불일치 위험이라는 새로운 트레이드오프를 낳습니다. 만약 사용자가 리뷰를 작성하거나, 관리자가 카테고리 이름을 수정할 경우, products 테이블에 중복 저장된 데이터의 정합성을 어떻게 보장할 수 있을지 최소 2 가지 이상의 전략을 비교하여 설명하시오.

> **[답변]**
> **전략 1: 애플리케이션 레벨 트랜잭션 (Strong Consistency)**
> - **방식:** 리뷰 작성 등 쓰기 로직에서 트랜잭션을 걸고, `reviews` 테이블 Insert와 `products` 테이블의 `avg_rating` Update를 원자적(Atomic)으로 수행합니다.
> - **장점:** 데이터 불일치 구간이 존재하지 않아 항상 정확한 데이터를 보여줍니다.
> - **단점:** 쓰기 트랜잭션이 길어지며, DB 락(Lock) 경합으로 인해 쓰기 성능이 저하될 수 있습니다.
>
> **전략 2: 비동기 이벤트 기반 최종 일관성 (Eventual Consistency)**
> - **방식:** 리뷰가 작성되면 메시지 큐(Kafka, RabbitMQ)에 이벤트를 발행하고, 별도의 워커(Worker) 프로세스가 이벤트를 소비하여 `products` 테이블의 통계 정보를 갱신합니다.
> - **장점:** 사용자 응답 시간이 빠르며, 쓰기 로직과 집계 로직의 결합도를 낮출 수 있습니다.
> - **단점:** 아주 짧은 시간 동안 사용자가 작성한 리뷰가 평점에 즉시 반영되지 않을 수 있습니다(Sync Lag).

4. **아키텍처적 접근**: 비정규화가 기존 OLTP 데이터베이스를 너무 복잡하게 만든다고 판단될 경우, 어떤 대안을 고려할 수 있을까요? 읽기(Query)용 모델과 쓰기용 모델을 분리하는 CQRS(Command Query Responsibility Segregation) 패턴의 관점에서, 분석/조회 전용의 읽기 전용 저장소를 별도로 구축하는 접근법의 장단점을 비정규화 전략과 비교하여 논하시오.

> **[답변]**
> **CQRS 패턴 적용 (Read/Write 저장소 분리):**
> 기존 RDB는 쓰기 전용(Command)으로 정규화를 유지하고, 읽기 전용(Query) 저장소로 **Elasticsearch**나 **NoSQL(MongoDB)** 등을 도입하여 조회 화면에 최적화된 형태의 데이터를 동기화하는 방식입니다.
>
> - **장점:**
>   - 복잡한 검색 조건이나 통계 쿼리를 RDB 부하 없이 처리할 수 있습니다.
>   - 읽기 모델을 UI 요구사항에 맞춰 자유롭게 변경해도 원본 데이터 모델(쓰기 모델)에 영향을 주지 않습니다.
> - **단점:**
>   - 인프라 복잡도가 크게 증가합니다 (별도 DB 운영, 동기화 파이프라인 구축 등).
>   - 데이터 복제 지연(Replication Lag)에 대한 처리가 필요합니다.
> - **비정규화와의 비교:** 단순한 컬럼 추가(비정규화)보다 구현 비용은 높지만, 시스템 규모가 커지고 조회 패턴이 다양해질수록 확장성 면에서 훨씬 유리합니다.

---

## 데이터베이스 설계 심층 탐구: 초거대 물류 플랫폼의 성능 병목 해결

### 상황
당신은 B2B 스마트 물류 플랫폼 'Logis-Flow'의 백엔드 수석 엔지니어로 합류했습니다. Logis-Flow 는 여러 고객사(화주, 운송사)의 상품 입고부터 창고 관리, 최종 목적지 배송까지 전 과정을 추적하고 관리하는 SaaS 솔루션입니다. 서비스 초기, 데이터베이스는 데이터 정합성과 확장성을 최우선으로 고려하여 제 3 정규형을 철저히 준수하여 설계되었습니다.

서비스가 폭발적으로 성장하며 하루에 수백만 건의 물류 이동이 발생하자, 시스템의 핵심 기능인 '실시간 화물 추적 대시보드'에서 심각한 성능 문제가 발생하기 시작했습니다. 이 대시보드는 고객사가 특정 화물(Shipment)의 현재 상태를 한눈에 파악하는 가장 중요한 화면입니다. 이 화면을 렌더링하기 위해 시스템은 다음과 같은 정보를 조합해야 합니다.

- 화물의 고유 ID, 출발 창고 이름, 도착 창고 주소
- 화물의 현재 상태(예: '집화 완료', '터미널 간 이동 중', '배송 중')와 최종 업데이트 시각
- 화물에 포함된 모든 상품의 이름과 수량
- 해당 화물이 생성된 이후 발생한 모든 상태 변경 이력(타임라인)

시스템의 데이터베이스 스키마는 다음과 같이 정규화되어 있습니다.
- `companies`: 고객사 정보 (약 1 만 개)
- `warehouses`: 창고 정보, 주소 포함 (약 5 만 개)
- `products`: 상품 마스터 정보 (약 1 천만 개)
- `shipments`: 화물 정보. origin_warehouse_id, destination_warehouse_id 를 외래 키로 가짐 (누적 5 억 건)
- `shipment_items`: shipments 와 products 를 잇는 다대다 관계 테이블 (누적 50 억 건)
- `shipment_updates`: 모든 화물의 상태 변경 기록이 append-only 방식으로 저장되는 로그 테이블. shipment_id, status_code, timestamp, notes 등의 컬럼을 가짐 (누적 500 억 건)

대시보드 로딩 시, 단일 화물 정보를 조회하는 쿼리는 shipments 테이블을 시작으로 warehouses 테이블을 두 번 조인하고, shipment_items 와 products 를 조인합니다. 가장 치명적인 부분은 화물의 '현재 상태'를 가져오기 위해 500 억 건의 shipment_updates 테이블에서 특정 shipment_id 에 해당하는 기록 중 timestamp 가 가장 최신인 1 건을 찾아야 한다는 점입니다. 또한, 상태 변경 이력 타임라인을 보여주기 위해 해당 shipment_id 의 모든 기록을 timestamp 순으로 정렬해야 합니다.

이 복합적인 쿼리는 피크 시간대에 10 초 이상 소요되어 고객의 불만을 야기하고 있으며, 데이터베이스의 읽기 전용 복제본(Read Replica) 마저 CPU 사용률이 100%에 달하는 상황을 만들고 있습니다.

### 문제

1. **병목의 근본 원인 분석**: 첫째, 현재의 정규화된 스키마가 왜 이토록 심각한 읽기 성능 저하를 유발하는지 데이터베이스의 내부 동작 원리와 연관 지어 분석하시오. 특히 거대한 로그성 테이블인 shipment_updates 에서 '가장 최신 상태' 하나를 조회하는 작업이 왜 본질적으로 비효율적인 연산인지 인덱스 전략과 데이터 스캔 범위의 관점에서 설명해야 합니다.

> **[답변]**
> **최신 상태 조회(Top-N Query, Limit 1)의 비효율성:**
> 500억 건의 테이블에서 `shipment_id`별 가장 최신(`ORDER BY timestamp DESC LIMIT 1`) 데이터를 찾는 것은 매우 고비용입니다.
>
> - **인덱스 스캔 부하:** (shipment_id, timestamp) 복합 인덱스가 있더라도, 목록 조회 시 N개의 화물 각각에 대해 인덱스 트리를 탐색(Index Seek)해야 합니다. 이를 **Loose Index Scan**이라고 하는데, 데이터 건수가 워낙 많아 인덱스 트리의 깊이(Height)가 깊고, 이로 인해 랜덤 I/O가 폭증합니다.
> - **Aggregate 부하:** 만약 `GROUP BY shipment_id` 후 `MAX(timestamp)`를 수행한다면, 인덱스를 타더라도 엄청난 범위의 데이터를 스캔해야 하므로 CPU와 I/O를 모두 소진하게 됩니다.

2. **비정규화 전략 제시**: 둘째, 이 문제를 해결하기 위한 첫 단계로써 비정규화 전략을 구체적으로 제시하시오. shipments 테이블의 구조를 어떻게 변경하여 대시보드 로딩에 필요한 조인 연산과 실시간 집계 작업을 최소화할 수 있을지 설명해야 합니다. 예를 들어, current_status, last_updated_at, origin_warehouse_name 과 같은 컬럼을 추가하는 방안을 포함하여 논리적인 스키마 변경안을 제안하시오.

> **[답변]**
> 대시보드 목록 조회 시 `JOIN`과 `Subquery`를 제거하는 방향으로 `shipments` 테이블을 비정규화합니다.
>
> **`shipments` 테이블 추가 컬럼:**
> - `current_status_code` (VARCHAR): 가장 최근 상태 코드를 바로 조회.
> - `last_updated_at` (TIMESTAMP): 가장 최근 업데이트 시간.
> - `origin_warehouse_name`, `destination_warehouse_name` (VARCHAR): 창고명을 바로 표시하여 2번의 JOIN 제거.
>
> 이제 500억 건 테이블을 뒤질 필요 없이, `shipments` 테이블만 조회하면 현재 상태를 즉시 알 수 있습니다.

3. **새로운 트레이드오프 분석**: 셋째, 당신이 제안한 비정규화 전략은 쓰기 경로의 복잡성을 증가시키고 데이터 정합성을 해칠 새로운 위험을 내포합니다. 새로운 상태 변경이 shipment_updates 테이블에 삽입될 때마다, shipments 테이블에 비정규화된 current_status 와 같은 컬럼의 값을 어떻게 일관성 있게 유지할 것인지 세 가지 서로 다른 아키텍처적 접근법, 즉 동기적 애플리케이션 트랜잭션, 데이터베이스 트리거, 그리고 메시지 큐를 활용한 비동기적 최종 일관성 모델의 장단점을 각각 비교하여 설명하시오.

> **[답변]**
> **1. 동기적 애플리케이션 트랜잭션**
> - **방식:** 코드 레벨에서 `INSERT update`와 `UPDATE shipment`를 하나의 트랜잭션으로 묶습니다.
> - **장점:** 데이터 정합성이 완벽하게 보장됩니다.
> - **단점:** DB Lock 점유 시간이 길어져 동시 처리량이 줄어들 수 있습니다.
>
> **2. 데이터베이스 트리거 (Trigger)**
> - **방식:** `shipment_updates` 테이블에 `AFTER INSERT` 트리거를 걸어 DB가 자동으로 `shipments`를 업데이트하도록 합니다.
> - **장점:** 애플리케이션 코드를 수정할 필요가 없습니다.
> - **단점:** DB에 숨겨진 로직이 생겨 유지보수가 어렵고, 대량 INSERT 시 트리거 부하로 DB 성능이 급감할 수 있습니다.
>
> **3. 메시지 큐 비동기 처리 (Eventual Consistency) - 추천**
> - **방식:** 상태 변경 요청 시 `updates`에는 바로 쓰고, `shipments` 갱신은 Kafka 등의 큐를 통해 비동기로 처리합니다.
> - **장점:** 사용자 요청 응답이 가장 빠르고, DB 쓰기 부하를 분산할 수 있습니다.
> - **단점:** 큐 지연 시 잠시동안 상태가 다르게 보일 수 있습니다.

4. **아키텍처적 접근**: 넷째, 대시보드의 '상태 변경 이력 타임라인' 기능은 여전히 shipment_updates 테이블의 많은 데이터를 읽어야 하는 부담을 안고 있습니다. 이 특정 조회 패턴을 최적화하기 위해, 기존 관계형 데이터베이스의 기능을 심화 활용하는 방안과 외부 시스템을 도입하는 방안을 각각 제시하고 비교하시오. PostgreSQL 의 테이블 파티셔닝 기능을 활용하는 방안과, 이력 데이터를 로그 분석이나 시계열 데이터 처리에 최적화된 외부 데이터 저장소, 예를 들어 Elasticsearch 나 DynamoDB 로 이관하는 방안의 기술적 트레이드오프를 논하시오.

> **[답변]**
> **방안 1: RDB 테이블 파티셔닝 (Partitioning)**
> - **내용:** `shipment_updates` 테이블을 `timestamp` 기준(월별/년별)으로 파티셔닝합니다.
> - **장점:** 오래된 데이터가 물리적으로 분리되어, 최근 데이터 조회 시 스캔 범위가 줄어듭니다. 관리 비용(오래된 파티션 삭제 등)이 저렴합니다.
> - **단점:** 여전히 단일 DB 리소스를 사용하므로 부하 분산에 한계가 있습니다.
>
> **방안 2: NoSQL 이관 (DynamoDB / Elasticsearch)**
> - **내용:** 이력 데이터는 조회 전용이므로, `shipment_id`를 파티션 키로 하는 DynamoDB나 Elasticsearch로 데이터를 동기화하여 서비스합니다.
> - **장점:** Key-Value 조회나 시계열 조회에 최적화되어 수십억 건 데이터에서도 일정한 응답 속도(O(1))를 보장합니다. 컴퓨팅 자원을 RDB와 분리할 수 있습니다.
> - **단점:** 별도 저장소 비용 및 데이터 동기화 파이프라인 구축 비용이 발생합니다.

5. **데이터 생명주기 관리**: 다섯째, shipment_updates 테이블은 시간이 지남에 따라 무한히 커질 것이 자명합니다. 서비스의 법적 요구사항과 운영 비용을 고려하여, 데이터 생명주기 관리 전략을 수립하시오. 예를 들어, 배송이 완료된 지 2 년이 지난 화물의 상태 변경 이력은 어떻게 처리할 것인지, 운영 데이터베이스에서 저비용의 장기 보관 스토리지, 예를 들어 AWS S3 Glacier 로 데이터를 안전하게 이전하고 필요시 다시 조회할 수 있는 아카이빙 프로세스를 구체적으로 설계하시오.

> **[답변]**
> **데이터 수명 주기(ILM) 전략:**
> 1.  **HOT 데이터 (운영 DB):** 최근 3~6개월(또는 진행 중인 건) 데이터는 고성능 RDB에 유지하여 즉시 조회 가능하게 합니다.
> 2.  **WARM 데이터 (NoSQL/Data Lake):** 6개월~1년 지난 데이터는 저렴한 NoSQL이나 조회 가능한 S3(Athena 활용) 영역으로 옮겨 가끔 발생하는 조회 요청을 처리합니다.
> 3.  **COLD 데이터 (S3 Glacier):** 법적 보관 의무(예: 3~5년)가 있는 데이터는 압축 후 AWS S3 Glacier Deep Archive 같은 최저가 스토리지로 보냅니다. 이는 복구에 시간이 걸리지만 비용이 매우 저렴합니다. 운영 DB에서는 해당 데이터를 삭제(`DELETE` or `DROP PARTITION`)하여 성능을 유지합니다.

---

## 리눅스 시스템 심층 탐구: 대규모 라이브 스트리밍 플랫폼의 병목 분석과 튜닝

### 상황
당신은 전 세계 수백만 명의 사용자를 보유한 라이브 스트리밍 플랫폼 **'Core-Stream'**의 SRE(Site Reliability Engineer)로 근무하고 있습니다. Core-Stream 의 핵심 백엔드 시스템은 방송인이 송출하는 고화질 원본 영상(RTMP)을 입력받아, 실시간으로 1080p, 720p, 480p 등 여러 화질로 트랜스코딩하고, 이를 HLS 또는 DASH 포맷의 작은 비디오 조각(Segment)으로 만들어 수만 명의 시청자에게 동시 전송하는 역할을 합니다.

이 시스템은 고성능 C++ 애플리케이션으로 구현되어 있으며, 다수의 Ubuntu 22.04 LTS 서버 클러스터 위에서 동작합니다. 평상시 수천 명의 시청자가 접속하는 환경에서는 아무런 문제가 없지만, e 스포츠 결승전이나 인기 스트리머의 특별 방송과 같이 서버당 동시 접속자가 5 만 명을 초과하는 대규모 이벤트가 발생할 때마다, 특정 서버들에서 영상 버퍼링이 심해지고 간헐적인 끊김 현상이 발생한다는 보고가 급증합니다.

기술팀의 초기 분석 결과는 더욱 혼란스러웠습니다. 문제의 서버들은 CPU 의 사용자 시간(us)과 시스템 시간(sy) 점유율이 합계 50% 미만으로 여유가 있었고, 메모리 사용량이나 네트워크 인터페이스의 대역폭(Bandwidth) 역시 한계치에 도달하지 않았습니다. 하지만 top 이나 htop 으로 CPU 상태를 상세히 들여다보면, **'si'**로 표시되는 소프트웨어 인터럽트(softirq) 처리 시간이 비정상적으로 높게 치솟는 현상이 관찰되었습니다. 또한, netstat 으로 네트워크 통계를 확인하면 TCP 소켓의 수신 큐가 가득 차 패킷이 버려지는 'listen queue overflows' 카운터가 급증하고 있었고, 애플리케이션 로그에는 간헐적으로 'Too many open files' 오류가 기록되기도 했습니다.

### 문제

1. **병목 원인 분석 (Softirq)**: 첫째, 시스템의 가장 명백한 이상 징후인 높은 소프트웨어 인터럽트(softirq) CPU 사용률의 근본 원인을 설명하시오. 리눅스 커널의 네트워크 스택에서 소프트웨어 인터럽트가 어떤 역할을 하는지 설명하고, 이 현상이 왜 '애플리케이션이 바쁜 것'과는 다른 차원의 문제이며, 오히려 커널 수준에서 네트워크 패킷을 처리하는 데 모든 자원을 소모하고 있음을 시사하는지 그 이유를 논리적으로 분석해야 합니다. 또한, cat /proc/softirqs 나 perf 와 같은 도구를 사용하여 수많은 소프트웨어 인터럽트 유형 중 구체적으로 어떤 항목(예: NET_RX)이 병목을 일으키고 있는지 특정하는 과정을 설명하시오.

> **[답변]**
> **Softirq(si) 병목 원인:**
> 리눅스 커널은 네트워크 패킷이 도착하면 하드웨어 인터럽트(Hard IRQ)로 최소한의 처리만 하고, 패킷의 디코딩이나 프로토콜 스택 처리는 소프트웨어 인터럽트(Softirq) 단계로 미뤄서 처리합니다.
>
> - **현상 분석:** `si`가 높다는 것은 애플리케이션(User Space)이 일을 하기 전에, 밀려드는 막대한 양의 패킷을 커널(Kernel Space)이 까서 분류하는 것만으로 CPU를 다 쓰고 있다는 뜻입니다. 즉, 애플리케이션 로직 문제가 아니라 **네트워크 패킷 처리 과부하** 문제입니다.
> - **확인 방법:** 터미널에서 `cat /proc/softirqs` 명령어를 반복 실행하여 `NET_RX` (Network Receive) 카운트가 급격히 증가하는지 확인하거나, `perf top` 명령어로 커널 함수 중 네트워크 관련 함수가 상위에 랭크되는지 확인하여 진단합니다.

2. **커널 파라미터 튜닝**: 둘째, 대규모 동시 접속으로 인한 TCP listen queue overflow 와 패킷 손실 문제를 해결하기 위한 커널 네트워크 파라미터 튜닝 전략을 제시하시오. sysctl 명령을 통해 변경할 수 있는 리눅스 커널의 핵심 파라미터 중 최소 세 가지 이상을 선택하고, 각 파라미터(예: net.core.somaxconn, net.core.netdev_max_backlog, net.ipv4.tcp_max_syn_backlog)가 구체적으로 무엇을 제어하며, 이 값을 상향 조정하는 것이 현재 문제 상황을 어떻게 개선할 수 있는지 상세히 설명해야 합니다.

> **[답변]**
> **커널 파라미터 튜닝 전략 (`/etc/sysctl.conf`):**
> 1.  **`net.core.somaxconn` (Socket Listen Queue):** 애플리케이션이 `accept()`를 호출하기 전에 대기하는 연결 완료 큐의 크기입니다. 기본값(보통 128~4096)이 작으면 5만 명 동시 접속 시 큐가 넘쳐 연결이 거절됩니다. 이를 65535 등으로 크게 늘려야 합니다.
> 2.  **`net.ipv4.tcp_max_syn_backlog` (SYN Backlog):** 3-way Handshake 중인(SYN_RECV) 반쯤 열린 연결을 저장하는 큐입니다. 대규모 접속 시도 시 이 큐가 차면 패킷 드롭이 발생하므로 값을 늘려줘야 합니다.
> 3.  **`net.core.netdev_max_backlog` (NIC Queue):** 랜카드(NIC)에서 커널로 패킷이 전달되기 전 대기하는 큐입니다. 패킷 유입 속도가 커널 처리 속도보다 빠를 때 버퍼 역할을 하도록 늘려줍니다.

3. **File Descriptor 제한 해제**: 셋째, 'Too many open files' 오류는 단순한 문제가 아님을 설명하시오. 리눅스에서 파일 디스크립터(File Descriptor) 제한이 프로세스별 제한과 시스템 전역 제한으로 나뉘어 관리된다는 점을 지적하고, 이 두 가지 제한의 차이점과 각각을 확인하고 영구적으로 변경하는 방법(예: /etc/security/limits.conf, /etc/sysctl.conf)을 설명해야 합니다. 특히, 수만 개의 동시 TCP 연결을 유지해야 하는 Core-Stream 의 애플리케이션이 왜 기본 설정값을 쉽게 초과할 수밖에 없는지 그 구조적 이유를 분석하시오.

> **[답변]**
> **File Descriptor (FD) 제한 설정:**
> 리눅스에서는 모든 네트워크 소켓을 '파일'로 취급합니다.
> - **구조적 이유:** 동시 접속자가 5만 명이면 최소 5만 개의 소켓 FD가 필요합니다. 하지만 리눅스 기본 설정(`ulimit -n`)은 보통 1,024개로 설정되어 있어 오류가 발생합니다.
> - **설정 방법:**
>   - **Process Level:** `/etc/security/limits.conf` 파일에서 `soft nofile 65535`, `hard nofile 65535` 등을 추가하여 사용자별/프로세스별 최대 열기 가능 파일 수를 늘립니다.
>   - **System Level:** `/proc/sys/fs/file-max` 값을 확인하고 `sysctl -w fs.file-max=...`로 시스템 전체가 열 수 있는 파일 총합 한계를 늘려줍니다.

4. **I/O Multiplexing (Epoll)**: 넷째, 문제의 근원은 애플리케이션이 수만 개의 네트워크 연결을 처리하는 방식 자체에 있을 수 있습니다. 전통적인 select 나 poll 과 같은 동기적 I/O 다중화(Multiplexing) 모델이 왜 이러한 초고성능 환경에 부적합한지 그 확장성의 한계를 설명하시오. 이어서, 현대적인 리눅스 애플리케이션이 사용하는 epoll 시스템 콜이 어떻게 커널의 도움을 받아 이 문제를 해결하는지, epoll 의 이벤트 기반(event-driven) 및 엣지 트리거(edge-triggered) 동작 방식이 어떻게 수만 개의 유휴 연결을 효율적으로 무시하고 활성 연결에만 집중하여 CPU 낭비를 막고 응답성을 높이는지 그 내부 동작 원리를 심층적으로 설명하시오.

> **[답변]**
> **Select/Poll vs Epoll:**
> - **Select/Poll의 한계:** 관리하는 연결(FD)이 5만 개라면, 매번 이 5만 개 리스트 전체를 커널에 복사하고, 루프를 돌며 상태를 확인해야 합니다(O(N)). 연결이 많아질수록 기하급수적으로 느려집니다.
> - **Epoll의 혁신:**
>   - **이벤트 기반 (O(1)):** 관찰 대상을 커널에 한 번 등록해두면, 실제 데이터가 도착한(Active) 소켓만 리턴해줍니다. 5만 개가 연결되어 있어도 10개만 데이터를 보내면 10개만 처리하면 됩니다.
>   - **Edge Trigger:** 상태가 변하는 순간(예: 데이터 도착 시)에만 딱 한 번 이벤트를 발생시켜, 불필요한 이벤트 중복 처리를 막고 고성능 Non-blocking I/O 처리를 가능하게 합니다.

---

## REST API 심층 탐구: 실시간 주문 처리 시스템의 상태 전이와 동시성 제어

### 상황
당신은 국내 최대 음식 배달 플랫폼 **'QuickEats'**의 주문 처리 마이크로서비스를 담당하는 백엔드 엔지니어입니다. 이 서비스는 고객, 레스토랑, 라이더라는 세 명의 행위자(Actor) 사이의 복잡한 상호작용을 관장하며, 주문의 전체 생명주기를 관리하는 REST API 를 외부에 제공합니다.

서비스 V1 API 는 초기에 빠른 개발을 위해 주문(Order)이라는 단일 리소스를 중심으로 설계되었습니다. 하지만 일일 주문량이 수백만 건을 넘어서면서, V1 API 의 설계적 한계가 명확한 기술 부채로 돌아오고 있습니다.

**주문(Order)의 핵심 생명주기:**
`결제 대기중` → `결제 실패` 또는 `주문 접수 대기중` → `주문 거절됨` 또는 `조리중` → `픽업 대기중` → `배달중` → `배달 완료`

**현재 V1 API 의 문제점:**
- **모호한 상태 전이 API:** `PUT /api/v1/orders/{order_id}`로 `{ "status": "new_status" }`만 보내 처리하여 비즈니스 로직 파악이 어렵습니다.
- **동시성 문제(Race Condition):** 주문 취소와 주문 접수가 동시에 일어날 때 데이터 불일치가 발생합니다.
- **멱등성(Idempotency) 부재:** 결제 재시도 시 중복 결제 위험이 있습니다.
- **N+1 문제:** 목록 조회 시 관련 정보를 얻기 위해 추가 호출이 필요합니다.

### 문제

1. **상태 전이 API 재설계**: 첫째, V1 API 의 모호한 상태 전이 문제를 해결하기 위해, 주문의 생명주기를 RESTful 하게 표현하는 API 를 새롭게 설계하시오. PUT 메서드에 의존하는 대신, 주문의 상태를 변경시키는 각 '행위' 자체를 리소스로 간주하는 '행위 기반 리소스(Action-oriented Resource)' 접근법을 사용하여 API 엔드포인트를 설계해야 합니다. 예를 들어, 레스토랑의 '주문 접수' 행위나 고객의 '주문 취소' 행위를 위한 구체적인 엔드포인트(HTTP 메서드와 URI 경로)를 제시하고, 이러한 설계가 왜 V1 에 비해 시스템의 비즈니스 규칙을 더 명확하게 만들고 확장성을 높이는지 설명하시오.

> **[답변]**
> **Action-oriented Resource 설계:**
> 단순 상태 필드 업데이트(`PUT`)가 아니라, 명확한 행위를 리소스로 정의합니다.
> - **주문 접수:** `POST /api/v2/orders/{order_id}/accept`
> - **주문 거절:** `POST /api/v2/orders/{order_id}/reject`
> - **주문 취소:** `POST /api/v2/orders/{order_id}/cancel`
> - **장점:** API URL만 봐도 어떤 비즈니스 행위가 일어나는지 명확합니다. 또한 '접수' 시에는 '조리 시간' 파라미터가 필요하고, '거절' 시에는 '거절 사유'가 필요하듯, 각 행위별로 필요한 데이터 검증 로직을 분리하여 구현하기 쉽습니다.

2. **멱등성 보장 (Idempotency)**: 둘째, 결제 재시도 시 중복 처리 문제를 방지하기 위해 멱등성을 어떻게 보장할 것인지 설명하시오. 클라이언트가 네트워크 오류 발생 시 안전하게 재시도할 수 있도록, POST /api/v2/orders/{order_id}/payment 와 같은 엔드포인트를 어떻게 수정해야 하는지 Idempotency-Key 헤더를 활용하는 표준적인 방법을 통해 그 요청-응답 흐름과 서버 측의 처리 로직을 상세히 기술해야 합니다.

> **[답변]**
> **멱등성(Idempotency) 구현 전략:**
> - **클라이언트:** 결제 요청 시 유니크한 키(UUID 등)를 생성하여 `Idempotency-Key: {UUID}` 헤더에 담아 보냅니다. 실패 후 재시도할 때도 **동일한 Key**를 보냅니다.
> - **서버:**
>   1. 요청이 오면 Key 저장소(Redis/DB)를 조회합니다.
>   2. **이미 존재하는 Key라면:** 로직을 실행하지 않고, 저장해두었던 이전 성공 응답(200 OK 등)을 그대로 반환합니다.
>   3. **처음 보는 Key라면:** 결제 로직을 수행하고, 결과 응답과 Key를 저장소에 저장한 뒤 클라이언트에 반환합니다.

3. **동시성 제어 (Optimistic Locking)**: 셋째, 고객의 '주문 취소'와 레스토랑의 '주문 접수'가 충돌하는 것과 같은 동시성 문제를 해결하기 위한 낙관적 락(Optimistic Locking) 전략을 API 수준에서 어떻게 구현할 수 있을지 설명하시오. HTTP 의 ETag 와 If-Match 조건부 요청 헤더를 사용하여, 클라이언트가 항상 리소스의 최신 버전을 기반으로 상태 변경을 시도하도록 보장하는 전체적인 과정을 설명해야 합니다. 만약 클라이언트가 오래된 버전의 정보를 기반으로 요청했을 때, 서버가 412 Precondition Failed 응답을 반환하여 충돌을 방지하는 시나리오를 포함하여 논하시오.

> **[답변]**
> **낙관적 락(Optimistic Locking)과 ETag 활용:**
> 1.  **조회(GET):** 클라이언트가 주문 정보를 조회하면 서버는 현재 데이터의 버전 해시값 등을 `ETag: "v10"` 헤더에 담아 줍니다.
> 2.  **수정 요청:** 클라이언트가 '취소' 요청을 보낼 때, 조회했던 버전을 `If-Match: "v10"` 헤더에 담아 보냅니다.
> 3.  **검증(Server):** 서버는 DB의 현재 버전과 `If-Match` 값을 비교합니다.
>     - **일치:** 정상 처리하고 버전을 v11로 업데이트합니다.
>     - **불일치(충돌):** 누군가 먼저 상태를 변경했다는 뜻이므로, `412 Precondition Failed` 에러를 반환합니다.
> 4.  **결과:** 클라이언트는 412 에러를 받으면 최신 상태를 다시 조회하고, 이미 '조리중'이라면 취소가 불가능함을 인지하게 되어 데이터 불일치를 막습니다.

4. **N+1 문제 해결**: 넷째, 클라이언트 앱의 N+1 조회 문제를 해결하기 위한 두 가지 서로 다른 데이터 제공 전략을 제시하고 비교하시오. 첫 번째로, RESTful API 의 유연성을 유지하면서 관련 리소스를 함께 포함하여 전달하는 '컴파운드 도큐먼트(Compound Document)' 또는 '사이드로딩(Side-loading)' 방식을 ?include=restaurant,rider 와 같은 쿼리 파라미터를 통해 어떻게 구현할 수 있는지 설명해야 합니다. 두 번째로, 대안적인 아키텍처로서 GraphQL 을 도입한다면 이 문제가 어떻게 더 근본적으로 해결될 수 있는지, 클라이언트가 필요한 데이터의 구조를 직접 정의하는 GraphQL 의 특징을 중심으로 두 방식의 장단점을 기술하시오.

> **[답변]**
> **전략 1: REST API Compound Document**
> - **방식:** `GET /orders?include=restaurant,rider` 처럼 쿼리 파라미터로 포함할 관계를 명시합니다. 서버는 응답 JSON에 주문 정보뿐 아니라 레스토랑과 라이더 객체를 중첩(Nested)하여 한 번에 내려줍니다.
> - **장단점:** 기존 REST 틀을 유지하며 해결 가능하지만, 응답 구조가 복잡해지고 필요 없는 필드까지 다 내려받는 오버헤드가 있습니다.
>
> **전략 2: GraphQL 도입**
> - **방식:** 클라이언트가 `query { orders { id status restaurant { name } rider { location } } }` 처럼 정확히 필요한 필드만 명시해서 요청합니다.
> - **장단점:** 화면별로 필요한 데이터가 달라도 API 변경 없이 대응 가능하며(Over-fetching 해결), 단 한 번의 요청으로 원하는 계층 구조 데이터를 모두 가져올 수 있습니다. 단, 서버 구현 복잡도가 높고 HTTP 캐싱 활용이 어렵습니다.

5. **API 버전 관리**: 다섯째, 기존 V1 API 를 사용하는 구버전 앱 사용자들을 중단 없이 지원하면서, 새로운 V2 API 를 안전하게 출시하기 위한 API 버전 관리 전략을 제시하시오. 가장 널리 사용되는 URI 경로 기반 버전 관리(예: /api/v2/...) 방식의 장점을 설명하고, 이를 Django 와 같은 웹 프레임워크에서 어떻게 구현할 수 있는지 기술해야 합니다.

> **[답변]**
> **URI Path Versioning:**
> - **전략:** `/api/v1/orders`와 `/api/v2/orders`를 동시에 운영합니다. 구버전 앱은 v1을 계속 호출하고, 업데이트된 앱은 v2를 호출합니다.
> - **장점:** 어떤 버전을 호출하는지 URL만으로 명확히 알 수 있어 디버깅과 로깅이 쉽습니다.
> - **Django 구현:** `urls.py`에서 URL 패턴을 분기합니다.
>   ```python
>   urlpatterns = [
>       path('api/v1/', include('orders.v1.urls')),
>       path('api/v2/', include('orders.v2.urls')),
>   ]
>   ```
>   이렇게 하면 v1용 뷰(View)와 v2용 뷰 코드를 완전히 분리하여, v2를 개발하다가 v1을 망가뜨리는 일을 방지할 수 있습니다.
